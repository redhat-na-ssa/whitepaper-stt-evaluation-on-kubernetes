ARG OS_VER=9
ARG CUDA=12.6.1
ARG IMAGE=nvcr.io/nvidia/cuda:${CUDA}-base-ubi${OS_VER}
FROM ${IMAGE}

# Python 3.11 is not included in the base UBI 9 repositories
ARG PYTHON_VER=3.9

# ADDED you can use the same Dockerfile for:
# Minimal builds with runtime model download
# Preloaded models for faster startup or air-gapped environments
# Optional model download at build time
ARG MODEL_SIZE  

# Switch to root for OS dependencies
USER root

# Install OS dependencies in a single step to reduce layers
RUN dnf install -y \
    python3 \
    python3-pip \
    gcc \
    git \
    make \
    libffi-devel \
    openssl-devel && \
    huggingface_hub && \
    dnf clean all

# Clone and build FFmpeg in one step
RUN git clone https://git.ffmpeg.org/ffmpeg.git \
      --branch "release/7.1" \
      --depth 1  \
      ffmpeg && \
    cd ffmpeg && \
      ./configure --help && \
      ./configure \
        --enable-gpl \
        --disable-ffplay \
        --disable-doc \
        --disable-x86asm && \
      make -j"$(nproc)" && \
      make install && \
    cd .. && \
      rm -rf ffmpeg

# Install vllm with CUDA 12.6.
RUN pip install vllm==0.8.5.post1 vllm[audio]==0.8.5.post1

# Install the model
RUN huggingface-cli download openai/whisper-tiny.en \
    --local-dir models/whisper-tiny.en \
    --local-dir-use-symlinks False \
    --repo-type model

# Install python packages
RUN pip${PYTHON_VER} install --no-cache-dir --upgrade pip==25.* && \
    pip${PYTHON_VER} install --no-cache-dir openai-whisper==20240930 jiwer==3.1.*

# Setup: entrypoint and other scripts over 
COPY --chmod=0755 bin /usr/local/bin

# Switch to non-root user
USER 1001

# Expose service on 8000
EXPOSE 8000

# Pass arguments to the entrypoint (api_server), just like the upstream vllm/vllm-openai image does.
# ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]

# Default command to process the audio file using ffmpeg & whisper
ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]
