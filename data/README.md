# Data Folder

Directory folders:

1. evaluations - scripts to evaluate model (whisper currently)
1. ground-truth - official transcriptions to evaluate accuracy
1. input-samples - provided audio files for transcription
1. metrics - .csv files from the evaluation scripts for performance analysis

## AI Model metrics

Captured from: whisper-functional-batch-metrics.sh → data/metrics/aiml_functional_metrics.csv

|Metric | Definition | Target/Ideal | Notes |
|-|-|-|-|
token_count | Tokens (words) generated by transcription | Should be stable per audio | Large shifts suggest inconsistent decoding
tokens_per_second | Transcription throughput (speed) | >10 (GPU), >2 (CPU) | Higher = better; compare cold vs warm starts
audio_duration | Audio length in seconds | Informational | Used for RTF calculation
real_time_factor (RTF) | Runtime ÷ audio duration | <1.0 (real-time); <0.5 ideal | Critical for latency-sensitive applications
container_runtime_sec | Total container lifespan (startup + task) | Lower = better | Cold starts include more overhead
wer (Word Error Rate) | % words wrong (substitution, deletion, insertion) | <5% = good; <1% = excellent | Primary accuracy measure
mer (Match Error Rate) | Mismatched words including edits | Should correlate with WER | Captures broader errors than WER alone
wil (Word Info Lost) | How much word meaning is lost | <0.3 preferred | Lower = better information preservation
wip (Word Info Preserved) | How much meaning is kept | >0.7 preferred | Complements WIL; higher = better
cer (Character Error Rate) | Character-level error | <2% clean audio; <5% noisy audio | Sensitive to fine transcription errors
threads | CPU threads used per job | Match configuration (e.g., 4–12) | Affects tokens/sec and container scaling
start_type | Cold = fresh container; Warm = reused container | Warm should be faster | Useful for analyzing startup overhead |

Quick Interpretation Tips:

- RTF <1.0 → Transcription faster than real-time.
- High tokens_per_second → More efficient model/inference.
- Stable token_count → Consistent transcription across runs.
- Low wer, cer → Higher quality transcriptions.
- Cold start vs Warm start → Helps you isolate container startup costs from pure model execution.

## Host metrics

Captured from: system_non_functional_monitoring.py → data/metrics/system_non_functional_metrics.csv
- columns: date,timestamp,container name,processor/gpu name,core/gpu count,max usage (%),max gpu temperature (C),max pwr:usage/cap (%),max vram usage (%),startup time (s),task time (s),shutdown time (s),total time (s),cpu usage (%),memory usage (MB)

Metric | Definition | Target / Interpretation |
|-|-|-|
processor/gpu name | Name of CPU or GPU used | Descriptive (e.g., "AMD EPYC", "NVIDIA L4")
core/gpu count | Number of CPU cores or GPUs detected | Should match system configuration
max usage (%) | Peak CPU or GPU utilization during job execution | CPU: ~90–100% expected; GPU: >50% for meaningful load
max gpu temperature (C) | Peak GPU temperature (°C) during inference | <85°C recommended; >90°C may impact lifespan
max pwr:usage/cap (%) | GPU power draw as % of maximum | 70–100% shows full load; <30% may suggest underutilization
max vram usage (%) | Max % of GPU memory used | <90% safe; >95% risks OOM errors
startup time (s) | Time to start container and load model | <60s for large models; <10s for small models
task time (s) | Actual transcription task duration | Should scale with audio duration and model complexity
shutdown time (s) | Time to stop container after transcription | Should be low (<2s); long shutdowns suggest cleanup delays
total time (s) | Total container lifecycle (startup + task + shutdown) | Useful for evaluating cold vs warm start differences
cpu usage (%) | Real-time CPU usage (peak or averaged) | >80% indicates good CPU saturation; <20% = underutilization
memory usage (MB) | RAM used during container execution | Monitor to prevent memory pressure (swap, OOM kills)

Quick Interpretation Guidelines:

- High CPU/GPU Utilization → Good resource usage.

- Low VRAM or Power Usage → Possible underload or small model.

- Long Startup Time → Image/model loading inefficiency; cold start cost.

- High Memory Usage → Risk of system swapping or failures with more jobs.

- Low CPU Usage → Possible I/O wait or model under-optimization.

Example Insights:

- "Am I fully utilizing my hardware?" → High CPU/GPU usage, high VRAM, high power draw.

- "Can I safely run more jobs concurrently?" → If CPU and memory usage have headroom.

- "Are my models ready for production?" → Fast startups, stable task times, efficient resource usage.

- "Is overheating an issue?" → Consistently high GPU temps (>85°C) would be a warning.